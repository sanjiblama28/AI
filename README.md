# AI-weekly activities

<br/>

>**Name: Sanjib Tamang**<br/>
>**ID: 12194939**<br/>
>**Course: AI Application System**<br/>
>**Professor: Mehdi Pirahandeh**<br/>

<br/>

### [Week-2](Week2_12190259.ipynb): <br/>
• Get Started with Google Colab<br/>
• Uploading data<br/>
• Importing Kaggle’s dataset<br/>
• Basic File Operations<br/>
<br/>

### [Week-3](Week3_12190259.ipynb): <br/>
**The backpropagation algorithm:<br/>**
• The forward pass<br/>
• The backward pass<br/>
<br/>

### [Week-4](Week4_12190259.ipynb): <br/>
**Fully Connected Networks Applied to Multiclass Classification:**<br/>
• Introduction to Datasets used when training networks<br/>
• Extending the network and learning algorithm to do multiclass classification<br/>
• Network for Digit Classification<br/>
• Loss Function for Multiclass Classification<br/>
• Programming Example: Classifying handwritten Digits<br/>
• Mini-Batch gradient descent<br/>

<br/>

### [Week-5](Week5_12190259.ipynb) | [Week-5, pt2](Week5_part2_12190259.ipynb): <br/>
• What is Tensorflow<br/>
• Computational graph<br/>
• Variables, Constants and Placeholders in TensorFlow<br/>
• Tensorboard visualization<br/>
• tf.summary.scalar command<br/>
• tf.summary.histogram command<br/>

<br/>

### [Week-6](Week6_12190259.ipynb) | [Week-6, pt2](Week6_12190259_session2.ipynb): <br/>
• Linear Regression using TensorFlow<br/>
• Visualization of Linear Regression parameters using TensorFlow<br/>
• Digit Classification | Neural network to classify MNIST dataset using TensorFlow<br/>

<br/>

### [Week-7](Week7_1_12190259.ipynb) | [Week-7, pt2](Week7_2_12190259.ipynb): <br/>
• Convolutional Neural Networks<br/>
• The CIFAR-10 Dataset<br/>
• Characteristics and building blocks for convolutionallayers<br/>
• Combining feature maps into a convolutional layer<br/>
• Combining convolutional and fully connected layers into anetwork<br/>
• Effects of sparse connections and weight sharing<br/>
• Image classification with a convolutional network<br/>
<br/>

### [Week-9](Week9_12190259.ipynb) | [Week-9, pt-2](Week9_2_12190259.ipynb): <br/>
• Logistic unit for binary classification<br/>
• Softmax unit for multiclass classification<br/>
• Linear unit for regression<br/>
• The Boston Housing dataset<br/>
• Predicting house prices with a DNN<br/>
• Improving generalization with regularization<br/>
• Experiment: Deeper and regularized models for house price prediction<br/>
• Concluding remarks on output units and regression problems<br/>
<br/>

### [Week-10](Week10_12190259.ipynb) | [Week-10, pt-2](Week10_2_12190259.ipynb): <br/>
#### Deeper CNNs and Pretrained Models <br/>
• VGGNet<br/>
• GoogLeNet<br/>
• ResNet<br/>
• Transfer Learning<br/>
• Data Augmentation as a Regularization Technique<br/>
• Mistakes made by CNNs<br/>
• Reducing parameters with Depthwise Separable Convolution<br/>
• Striking the right network design balance with EfficientNet<br/>
<br/>


### [Week-11](Week11_12190259.ipynb)
• Limitations of Feedforward Networks<br/>
• Recurrent Neural Networks<br/>
• Mathematical Representation of a Recurrent layer<br/>
• Combining layers into an RNN<br/>
• Alternative veiw of RNN and Unrolling in Time<br/>
• Backpropagation Through Time<br/>
• Programming Example: Forecasting book sales<br/>
<br/>
